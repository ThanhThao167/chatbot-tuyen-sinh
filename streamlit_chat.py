import os
import streamlit as st
import pandas as pd
import uuid
from dotenv import load_dotenv
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime
from functools import lru_cache

# Load API key t·ª´ .env
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# UI c·∫•u h√¨nh
st.set_page_config(page_title="Chatbot T∆∞ V·∫•n Tuy·ªÉn Sinh l·ªõp 10 tr∆∞·ªùng THPT Marie Curie", page_icon="üß†")
st.title("üß† Chatbot T∆∞ V·∫•n Tuy·ªÉn Sinh l·ªõp 10 tr∆∞·ªùng THPT Marie Curie")

# Kh·ªüi t·∫°o session
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []

# Load Q&A t·ª´ CSV
@lru_cache(maxsize=1)
def get_cached_qa_pairs():
    try:
        df = pd.read_csv("MC_chatbot.csv", encoding="utf-8")
        return list(zip(df['cauhoi'], df['cautraloi']))
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i d·ªØ li·ªáu: {e}")
        return []

@lru_cache(maxsize=1)
def get_vectorizer_and_matrix():
    qa_pairs = get_cached_qa_pairs()
    questions = [q for q, _ in qa_pairs]
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(questions)
    return vectorizer, tfidf_matrix

def find_best_match(query, qa_pairs):
    vectorizer, tfidf_matrix = get_vectorizer_and_matrix()
    query_vec = vectorizer.transform([query])
    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()
    idx = sims.argmax()
    score = sims[idx]
    return qa_pairs[idx][1], score

def save_chat_to_csv(session_id: str, role: str, content: str):
    history_file = "chat_history.csv"
    row = {
        "timestamp": datetime.now().isoformat(),
        "session_id": session_id,
        "role": role,
        "content": content
    }
    df = pd.DataFrame([row])
    if os.path.exists(history_file):
        df.to_csv(history_file, mode='a', index=False, header=False, encoding='utf-8')
    else:
        df.to_csv(history_file, mode='w', index=False, header=True, encoding='utf-8')

# Nh·∫≠p c√¢u h·ªèi
user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    save_chat_to_csv(st.session_state.session_id, "user", user_input)

    qa_pairs = get_cached_qa_pairs()
    if qa_pairs:
        answer, score = find_best_match(user_input, qa_pairs)
        if score >= 0.5:
            reply = answer
        else:
            try:
                context = st.session_state.messages[-3:] if len(st.session_state.messages) > 3 else st.session_state.messages
                completion = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": msg["role"], "content": msg["content"]} for msg in context
                    ]
                )
                reply = completion.choices[0].message.content
            except Exception as e:
                reply = f"‚ùå L·ªói khi g·ªçi GPT: {e}"
    else:
        reply = "‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ file CSV."

    st.session_state.messages.append({"role": "assistant", "content": reply})
    save_chat_to_csv(st.session_state.session_id, "assistant", reply)

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

st.divider()

# Hi·ªÉn th·ªã b·∫£ng l·ªãch s·ª≠
st.subheader("üìÇ L·ªãch s·ª≠ tr√≤ chuy·ªán (ghi nh·∫≠n t·ª´ chat_history.csv)")
try:
    df = pd.read_csv("chat_history.csv")
    df_filtered = df[df["session_id"] == st.session_state.session_id]
    st.dataframe(df_filtered[["timestamp", "role", "content"]], use_container_width=True)
except FileNotFoundError:
    st.info("Ch∆∞a c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ ƒë∆∞·ª£c l∆∞u.")
